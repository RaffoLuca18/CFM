{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f32e1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import data_gen as dg\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a7b105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_prob(sigma, i, h, J, beta=1.0):\n",
    "\n",
    "    local_field = h[i] + jnp.dot(J[i], sigma) - J[i, i] * sigma[i]\n",
    "    exponent = -2 * beta * sigma[i] * local_field\n",
    "\n",
    "    return 1.0 / (1.0 + jnp.exp(exponent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d2031ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_conditional_prob(sigma, i, h, J, beta=1.0):\n",
    "\n",
    "    return jnp.log(conditional_prob(sigma, i, h, J, beta) + 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a53b8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logp_given_mu(mu, samples, i, h, J, beta=1.0):\n",
    "\n",
    "    sigma = samples[mu]\n",
    "    \n",
    "    return log_conditional_prob(sigma, i, h, J, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dcc5a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logp_all_mu(mus, samples, i, h, J, beta=1.0):\n",
    "    \n",
    "    return jax.vmap(compute_logp_given_mu, in_axes=(0, None, None, None, None, None))(mus, samples, i, h, J, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "deaf8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_pseudolikelihood_site(samples, i, h, J, beta=1.0):\n",
    "\n",
    "    M = samples.shape[0]\n",
    "    mus = jnp.arange(M)\n",
    "    logps = compute_logp_all_mu(mus, samples, i, h, J, beta)\n",
    "    \n",
    "    return jnp.mean(logps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78d1803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_log_pseudolikelihood(samples, h, J, beta=1.0):\n",
    "    \n",
    "    d = samples.shape[1]\n",
    "    sites = jnp.arange(d)\n",
    "    site_logps = jax.vmap(log_pseudolikelihood_site, in_axes=(None, 0, None, None, None))(samples, sites, h, J, beta)\n",
    "\n",
    "    return jnp.sum(site_logps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e694964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_loss(samples, h, J, beta=1.0):\n",
    "    \n",
    "    return -total_log_pseudolikelihood(samples, h, J, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a9b23a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_gradients(samples, h, J, beta):\n",
    "\n",
    "    grad_loss = jax.grad(pl_loss, argnums=(1, 2))\n",
    "\n",
    "    return grad_loss(samples, h, J, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "672f6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_step(params, opt_state, samples, optimizer, beta):\n",
    "    \n",
    "    grad_h, grad_J = pl_gradients(samples, params[\"h\"], params[\"J\"], beta)\n",
    "\n",
    "    grads = {\n",
    "        \"h\": grad_h,\n",
    "        \"J\": grad_J\n",
    "    }\n",
    "\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "\n",
    "    J = params[\"J\"]\n",
    "    J = 0.5 * (J + J.T)\n",
    "    J = J - jnp.diag(jnp.diag(J))\n",
    "    params[\"J\"] = J\n",
    "\n",
    "    return params, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "090d6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_pl(samples, h_init, J_init, n_steps=1000, lr=1e-2, beta=1.0):\n",
    "    \n",
    "    params = {\n",
    "        \"h\": h_init,\n",
    "        \"J\": J_init\n",
    "    }\n",
    "\n",
    "    optimizer = optax.adam(lr)\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        params, opt_state = pl_step(params, opt_state, samples, optimizer, beta)\n",
    "\n",
    "        if t % 100 == 0:\n",
    "            loss_val = pl_loss(samples, params[\"h\"], params[\"J\"], beta)\n",
    "            print(f\"step {t} | loss = {loss_val:.6f}\")\n",
    "\n",
    "    return params[\"h\"], params[\"J\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2d0c2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0:[0.13600000739097595, -0.12300000339746475, -0.17000000178813934]\n",
      "[0.843000054359436, -0.7590000629425049, -0.64000004529953]\n",
      "0.13300001621246338\n",
      "\n",
      "step 500:[0.9440000653266907, -0.9040000438690186, -0.6480000019073486]\n",
      "[0.9830000400543213, -0.9410000443458557, -0.6610000133514404]\n",
      "0.0036666791420429945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = 3\n",
    "\n",
    "n_samples = 100000\n",
    "\n",
    "h, J = dg.generate_ising_params(d, sigma_h=1, sigma_J=0.5, seed=0)\n",
    "\n",
    "samples = dg.generate_ising_data(n_samples, h=h, J=J, n_steps=1000, beta=1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76442a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True h: [ 1.0040143 -0.9063372 -0.7481722]\n",
      "True J: [[ 0.         -1.1946154  -0.47133768]\n",
      " [-1.1946154   0.         -0.44069302]\n",
      " [-0.47133768 -0.44069302  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"True h:\", h)\n",
    "print(\"True J:\", J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b02a19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | loss = 1.688235\n",
      "step 100 | loss = 0.679922\n",
      "step 200 | loss = 0.679900\n",
      "step 300 | loss = 0.679900\n",
      "step 400 | loss = 0.679900\n",
      "step 500 | loss = 0.679900\n",
      "step 600 | loss = 0.679900\n",
      "step 700 | loss = 0.679900\n",
      "step 800 | loss = 0.679900\n",
      "step 900 | loss = 0.679900\n",
      "estimated h: [ 1.0040001 -0.896     -0.748    ]\n",
      "estimated J: [[ 0.         -1.1910001  -0.47400004]\n",
      " [-1.1910001   0.         -0.44000003]\n",
      " [-0.47400004 -0.44000003  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "h0 = 0.1 * jax.random.normal(key, shape=(d,))\n",
    "J0 = 0.1 * jax.random.normal(key, shape=(d, d))\n",
    "J0 = 0.5 * (J0 + J0.T)\n",
    "J0 = J0 - jnp.diag(jnp.diag(J0))\n",
    "\n",
    "h_est, J_est = optimize_pl(samples, h0, J0, n_steps=1000, lr=0.1, beta=1.0)\n",
    "\n",
    "print(\"estimated h:\", jnp.round(h_est, 3))\n",
    "print(\"estimated J:\", jnp.round(J_est, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
