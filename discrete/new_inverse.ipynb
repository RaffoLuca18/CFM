{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e77e9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Literal\n",
    "from jaxopt import LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bd044615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_samples(path: str | Path) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "\n",
    "    \"\"\"\n",
    "    returns\n",
    "    -------\n",
    "    freq : jnp.ndarray, shape (num_conf,) - sampling frequencies\n",
    "    configs : jnp.ndarray, shape (num_conf, num_spins) - spin configurations encoded as ±1\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    arr = df.values\n",
    "    freq = arr[:, 0].astype(np.float32)\n",
    "    configs = arr[:, 1:].astype(np.float32)\n",
    "    \n",
    "    return jnp.asarray(freq), jnp.asarray(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "62dd68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_adjacency(path: str | Path, n: int) -> jnp.ndarray:\n",
    "\n",
    "    \"\"\"\n",
    "    returns\n",
    "    -------\n",
    "    adj : jnp.ndarray, shape (n, n) - binary mask for allowed couplings\n",
    "    raises\n",
    "    ------\n",
    "    ValueError if the loaded matrix is not n x n\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    adj = df.values.astype(np.float32)\n",
    "    if adj.shape != (n, n):\n",
    "        raise ValueError(f\"adjacency must be {n} x {n}, got {adj.shape}\")\n",
    "    \n",
    "    return jnp.asarray(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e500d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_lambda(alpha: float, n_spins: int, n_samples: int) -> float:\n",
    "\n",
    "    \"\"\"\n",
    "    compute the regularization strength λ from\n",
    "    the user-supplied coefficient alpha\n",
    "\n",
    "    parameters\n",
    "    ----------\n",
    "    alpha : float\n",
    "        user-chosen coefficient (0 < alpha ≤ 1 typically)\n",
    "    n_spins : int\n",
    "        number of spins in the system\n",
    "    n_samples : int\n",
    "        total number of samples in the histogram\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    float\n",
    "        lambda value used in the l1 penalty term\n",
    "    \"\"\"\n",
    "\n",
    "    return alpha * math.sqrt(math.log((n_spins ** 2) / 0.05) / n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0f67e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rise_loss(h: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    rise loss: exp(-h)\n",
    "    \"\"\"\n",
    "    return jnp.exp(-h)\n",
    "\n",
    "\n",
    "def _logrise_loss(h: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    log-rise loss: same exponential inside, the log is taken\n",
    "    in the caller for numerical stability\n",
    "    \"\"\"\n",
    "    return jnp.exp(-h)\n",
    "\n",
    "\n",
    "def _rple_loss(h: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    rple loss: log(1 + exp(-2h))\n",
    "    \"\"\"\n",
    "    return jnp.log1p(jnp.exp(-2.0 * h))\n",
    "\n",
    "\n",
    "def _mpf1_loss(h: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    l_mpf ∝ exp(-ΔE / 2) with ΔE = 2h in the node-centric notation,\n",
    "    hence exp(-h)\n",
    "    \"\"\"\n",
    "    return jnp.exp(-h)  # equivalent to rise when written per‑node\n",
    "\n",
    "\n",
    "def _mpf2_loss(\n",
    "    h_s: jnp.ndarray,          # (N,)   – logit del nodo s\n",
    "    configs: jnp.ndarray,      # (N,d)  – campioni ±1\n",
    "    w_row: jnp.ndarray,        # (d,)   – vettore w_{s,·} già ricostruito\n",
    "    s: int,                    # indice del nodo centrale\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Local‑pair MPF2 loss per il nodo s.\n",
    "    Ritorna un vettore (N,) con, per ogni campione i,\n",
    "        L_i = Σ_{j≠s}  exp( -( h_s(i) - 2 J_{sj} x_s(i) x_j(i) ) ).\n",
    "    Quando verrà moltiplicato per freq/n_samples e sommato,\n",
    "    produce la loss scalare di MPF2 approssimata per il nodo s.\n",
    "    \"\"\"\n",
    "    # 1. prodotto spin‑spin x_s x_j  → shape (N,d)\n",
    "    prod = configs[:, s:s+1] * configs        # broadcasting sul secondo asse\n",
    "\n",
    "    # 2. ΔE/2 approssimato per tutte le j\n",
    "    #    delta_half_ij = h_s(i) - 2 * J_{sj} * x_s(i) * x_j(i)\n",
    "    delta_half = h_s[:, None] - 2.0 * w_row[None, :] * prod\n",
    "\n",
    "    # 3. escludi j = s (self‑flip non esiste)\n",
    "    delta_half = delta_half.at[:, s].set(jnp.inf)\n",
    "\n",
    "    # 4. exp(-ΔE/2) e somma su j ≠ s   →  vettore (N,)\n",
    "    return jnp.exp(-delta_half).sum(axis=1)\n",
    "\n",
    "\n",
    "def _cms1_loss(h: jnp.ndarray) -> jnp.ndarray:\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "986859b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxopt import LBFGS\n",
    "import jax.numpy as jnp\n",
    "from typing import Optional\n",
    "\n",
    "def _reconstruct_single_spin(\n",
    "    s: int,\n",
    "    freq: jnp.ndarray,\n",
    "    configs: jnp.ndarray,\n",
    "    method: str,\n",
    "    lam: float,\n",
    "    adj_row: Optional[jnp.ndarray],\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    reconstruct the coupling vector w_{s,·} for a single spin s\n",
    "    returns a vector of length num_spins\n",
    "    \"\"\"\n",
    "    num_conf, num_spins = configs.shape\n",
    "    n_samples = freq.sum()\n",
    "\n",
    "    # ----- local statistics -----\n",
    "    y = configs[:, s]\n",
    "    nodal_stat = y[:, None] * configs\n",
    "    nodal_stat = nodal_stat.at[:, s].set(y)\n",
    "    nodal_stat = nodal_stat.astype(jnp.float32)\n",
    "\n",
    "    # ----- masks -----\n",
    "    l1_mask = jnp.ones(num_spins, dtype=jnp.float32).at[s].set(0.0)\n",
    "    zero_mask = (\n",
    "        (adj_row == 0) & (jnp.arange(num_spins) != s)\n",
    "        if adj_row is not None\n",
    "        else jnp.zeros(num_spins, dtype=bool)\n",
    "    )\n",
    "\n",
    "    free_idx = jnp.where(~zero_mask)[0]\n",
    "    l1_mask_free = l1_mask[free_idx]\n",
    "\n",
    "    # ----- smooth part of the loss -----\n",
    "    def loss_smooth(w_free):\n",
    "        w_full = jnp.zeros(num_spins, dtype=jnp.float32).at[free_idx].set(w_free)\n",
    "        h = nodal_stat @ w_full\n",
    "\n",
    "        if method == \"RISE\":\n",
    "            return (freq / n_samples * _rise_loss(h)).sum()\n",
    "        elif method == \"logRISE\":\n",
    "            return jnp.log((freq / n_samples * _logrise_loss(h)).sum())\n",
    "        elif method == \"RPLE\":\n",
    "            return (freq / n_samples * _rple_loss(h)).sum()\n",
    "        elif method == \"MPF1\":\n",
    "            return (freq / n_samples * _mpf1_loss(h)).sum()\n",
    "        elif method == \"MPF2\":\n",
    "            mpf2_vec = _mpf2_loss(h, configs, w_full, s)      # <-- NEW\n",
    "            return (freq / n_samples * mpf2_vec).sum()        # <-- NEW\n",
    "        elif method == \"CMS1\":\n",
    "            return (freq / n_samples * _cms1_loss(h)).sum()\n",
    "        else:\n",
    "            raise ValueError(f\"unknown method: {method}\")\n",
    "\n",
    "    # ----- total objective (smooth + λ‖w‖₁) -----\n",
    "    def objective(w_free):\n",
    "        return loss_smooth(w_free) + lam * jnp.sum(l1_mask_free * jnp.abs(w_free))\n",
    "\n",
    "    # ----- lbfgs optimisation -----\n",
    "    init_w = jnp.zeros((free_idx.size,), dtype=jnp.float32)\n",
    "    solver = LBFGS(fun=objective, maxiter=500, tol=1e-6)\n",
    "    sol = solver.run(init_w)\n",
    "    w_opt_free = sol.params\n",
    "\n",
    "    # ----- re‑insert into full vector -----\n",
    "    w_full = jnp.zeros(num_spins, dtype=jnp.float32).at[free_idx].set(w_opt_free)\n",
    "    return w_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dfcaf109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_ising(\n",
    "    method: str,\n",
    "    regularizing_value: float,\n",
    "    symmetrization: str,\n",
    "    file_samples_histo: str | Path,\n",
    "    file_reconstruction: str | Path = \"reconstruction.csv\",\n",
    "    adjacency_path: Optional[str | Path] = None,\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    method = method.strip()\n",
    "    symmetrization = symmetrization.strip().upper()\n",
    "\n",
    "    freq, configs = _read_samples(file_samples_histo)\n",
    "    num_conf, num_spins = configs.shape\n",
    "    num_samples = float(freq.sum())\n",
    "\n",
    "    adj = None\n",
    "    if adjacency_path is not None:\n",
    "        adj = _read_adjacency(adjacency_path, num_spins)\n",
    "\n",
    "    lam = _compute_lambda(regularizing_value, num_spins, num_samples)\n",
    "    print(f\"λ = {lam:.5g}  (reg = {regularizing_value})\")\n",
    "\n",
    "    rows = []\n",
    "    for s in range(num_spins):\n",
    "        print(f\"[{s+1}/{num_spins}] reconstruction spin {s}\")\n",
    "        adj_row = adj[s] if adj is not None else None\n",
    "        w_row = _reconstruct_single_spin(\n",
    "            s, freq, configs, method, lam, adj_row\n",
    "        )\n",
    "        rows.append(w_row)\n",
    "\n",
    "    W = jnp.stack(rows)  # (n, n)\n",
    "\n",
    "    if symmetrization == \"Y\":\n",
    "        W = 0.5 * (W + W.T)\n",
    "\n",
    "    W_np = np.asarray(W)\n",
    "\n",
    "\n",
    "\n",
    "    pd.DataFrame(W_np).to_csv(file_reconstruction, header=False, index=False)\n",
    "    print(f\"matrix saved in '{file_reconstruction}'\")\n",
    "\n",
    "    return W_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "041e3550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters set manually:\n",
      "  method              = MPF2\n",
      "  regularizing_value  = 0.2\n",
      "  symmetrization      = Y\n",
      "  file_samples_histo  = output_samples.csv\n",
      "  file_reconstruction = reconstruction.csv\n",
      "  adjacency_path      = None\n",
      "λ = 0.0017193  (reg = 0.2)\n",
      "[1/9] reconstruction spin 0\n",
      "[2/9] reconstruction spin 1\n",
      "[3/9] reconstruction spin 2\n",
      "[4/9] reconstruction spin 3\n",
      "[5/9] reconstruction spin 4\n",
      "[6/9] reconstruction spin 5\n",
      "[7/9] reconstruction spin 6\n",
      "[8/9] reconstruction spin 7\n",
      "[9/9] reconstruction spin 8\n",
      "matrix saved in 'reconstruction.csv'\n",
      "reconstruction finished. matrix W:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.0600461 ,  0.04980823,  0.30988806,  0.37839773,  0.14727369,\n",
       "         0.1971815 ,  0.37445468,  0.14944658,  0.1928867 ],\n",
       "       [ 0.04980823, -0.3953902 ,  0.30482307,  0.14546314,  0.364671  ,\n",
       "         0.1878095 ,  0.14372538,  0.3684561 ,  0.19208546],\n",
       "       [ 0.30988806,  0.30482307, -0.05959792,  0.22110888,  0.21766832,\n",
       "         0.38837743,  0.21810174,  0.21324842,  0.39513752],\n",
       "       [ 0.37839773,  0.14546314,  0.22110888,  0.2963183 ,  0.36106896,\n",
       "         0.3834447 ,  0.402301  ,  0.21498173,  0.2349551 ],\n",
       "       [ 0.14727369,  0.364671  ,  0.21766832,  0.36106896, -0.04278917,\n",
       "         0.37854475,  0.21942544,  0.40298986,  0.23410495],\n",
       "       [ 0.1971815 ,  0.1878095 ,  0.38837743,  0.3834447 ,  0.37854475,\n",
       "         0.03043606,  0.23830417,  0.23858479,  0.4014634 ],\n",
       "       [ 0.37445468,  0.14372538,  0.21810174,  0.402301  ,  0.21942544,\n",
       "         0.23830417,  0.04636238,  0.36451495,  0.38468337],\n",
       "       [ 0.14944658,  0.3684561 ,  0.21324842,  0.21498173,  0.40298986,\n",
       "         0.23858479,  0.36451495, -0.0757318 ,  0.38061452],\n",
       "       [ 0.1928867 ,  0.19208546,  0.39513752,  0.2349551 ,  0.23410495,\n",
       "         0.4014634 ,  0.38468337,  0.38061452,  0.00569396]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "method              = \"MPF2\"       # \"RISE\", \"logRISE\", \"RPLE\", or \"MPF\"\n",
    "regularizing_value  = 0.2          # coefficient α (0 < α ≤ 1 is typical)\n",
    "symmetrization      = \"Y\"          # \"Y\" = symmetrize; \"N\" = keep asymmetric\n",
    "file_samples_histo  = \"output_samples.csv\"   # CSV with [freq, spin1, spin2, …]\n",
    "file_reconstruction = \"reconstruction.csv\"   # output file for the estimated matrix\n",
    "adjacency_path      = None          # set to a path if you have structural constraints\n",
    "# ────────────────────────────────────────────────\n",
    "\n",
    "# quick path checks\n",
    "file_samples_histo = Path(file_samples_histo)\n",
    "if not file_samples_histo.exists():\n",
    "    raise FileNotFoundError(f\"{file_samples_histo} not found\")\n",
    "\n",
    "if adjacency_path is not None:\n",
    "    adjacency_path = Path(adjacency_path)\n",
    "    if not adjacency_path.exists():\n",
    "        raise FileNotFoundError(f\"{adjacency_path} not found\")\n",
    "\n",
    "print(\"parameters set manually:\")\n",
    "print(f\"  method              = {method}\")\n",
    "print(f\"  regularizing_value  = {regularizing_value}\")\n",
    "print(f\"  symmetrization      = {symmetrization}\")\n",
    "print(f\"  file_samples_histo  = {file_samples_histo}\")\n",
    "print(f\"  file_reconstruction = {file_reconstruction}\")\n",
    "print(f\"  adjacency_path      = {adjacency_path}\")\n",
    "\n",
    "# ---- call inverse_ising ----\n",
    "W = inverse_ising(\n",
    "    method=method,\n",
    "    regularizing_value=regularizing_value,\n",
    "    symmetrization=symmetrization,\n",
    "    file_samples_histo=file_samples_histo,\n",
    "    file_reconstruction=file_reconstruction,\n",
    "    adjacency_path=adjacency_path,\n",
    ")\n",
    "\n",
    "print(\"reconstruction finished. matrix W:\")\n",
    "W  # Jupyter will render the matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7e34840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_error(\n",
    "    reco_csv: str | Path,\n",
    "    true_csv: str | Path,\n",
    "    norm: Literal[\"fro\", \"l1\", \"l2\", \"max\"] = \"fro\",\n",
    "    ignore_diag: bool = False,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    compare reconstructed couplings with ground-truth adjacency\n",
    "\n",
    "    parameters\n",
    "    ----------\n",
    "    reco_csv : path to reconstruction.csv (estimated matrix)\n",
    "    true_csv : path to input_adjacency.csv (ground-truth matrix)\n",
    "    norm      : which matrix norm to compute\n",
    "                \"fro\" → frobenius (default)\n",
    "                \"l1\"  → entry-wise absolute sum\n",
    "                \"l2\"  → spectral norm (largest singular value)\n",
    "                \"max\" → max |diff|\n",
    "    ignore_diag : if true, set the diagonal of both matrices to 0\n",
    "                  before computing the norm (useful if fields h_i\n",
    "                  are in the diagonal and you only care about J_ij)\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    float - requested norm of (reco - true)\n",
    "    \"\"\"\n",
    "    reco = pd.read_csv(reco_csv, header=None).values.astype(float)\n",
    "    true = pd.read_csv(true_csv, header=None).values.astype(float)\n",
    "\n",
    "    if reco.shape != true.shape:\n",
    "        raise ValueError(f\"shape mismatch: {reco.shape} vs {true.shape}\")\n",
    "\n",
    "    if ignore_diag:\n",
    "        np.fill_diagonal(reco, 0.0)\n",
    "        np.fill_diagonal(true, 0.0)\n",
    "\n",
    "    diff = reco - true\n",
    "\n",
    "    if norm == \"fro\":\n",
    "        return np.linalg.norm(diff, \"fro\")\n",
    "    elif norm == \"l1\":\n",
    "        return np.sum(np.abs(diff))\n",
    "    elif norm == \"l2\":\n",
    "        return np.linalg.norm(diff, 2)\n",
    "    elif norm == \"max\":\n",
    "        return np.max(np.abs(diff))\n",
    "    else:\n",
    "        raise ValueError(f\"unknown norm '{norm}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9843b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frobenius error = 1.4824977231105307\n",
      "l1 error (off-diag) = 12.024665248\n"
     ]
    }
   ],
   "source": [
    "err_fro = reconstruction_error(\"reconstruction.csv\", \"input_adjacency.csv\", norm=\"fro\")\n",
    "print(\"frobenius error =\", err_fro)\n",
    "\n",
    "err_l1  = reconstruction_error(\"reconstruction.csv\", \"input_adjacency.csv\", norm=\"l1\", ignore_diag=True)\n",
    "print(\"l1 error (off-diag) =\", err_l1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
