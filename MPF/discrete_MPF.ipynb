{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3cc459fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import data_gen as dg\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b10b9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_spin(sigma, i):\n",
    "    return sigma.at[i].set(-sigma[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03dd7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_energy_diff(sigma, i, h, j):\n",
    "    \"\"\"\n",
    "    Compute energy difference E(new_sigma) - E(sigma) when flipping spin i\n",
    "    \"\"\"\n",
    "    delta = 2 * sigma[i] * (h[i] + jnp.dot(j[i], sigma) - j[i, i] * sigma[i])\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f54272e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpf_loss_single_sample(sigma, h, j, beta=1.0):\n",
    "    \"\"\"\n",
    "    Compute the MPF loss for a single sample sigma using an explicit loop\n",
    "    \"\"\"\n",
    "    d = sigma.shape[0]\n",
    "    loss = 0.0\n",
    "\n",
    "    for i in range(d):\n",
    "        delta_e = local_energy_diff(sigma, i, h, j)\n",
    "        loss += jnp.exp(-0.5 * beta * delta_e)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "712b78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy_differences_all_sites(sigma, h, j):\n",
    "    \"\"\"\n",
    "    Return vector of energy differences for all single-spin flips of one configuration\n",
    "    \"\"\"\n",
    "    d = sigma.shape[0]\n",
    "    diffs = []\n",
    "\n",
    "    for i in range(d):\n",
    "        delta_e = local_energy_diff(sigma, i, h, j)\n",
    "        diffs.append(delta_e)\n",
    "\n",
    "    return jnp.array(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ecaa7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpf_loss_per_sample(sigma, h, j, beta):\n",
    "    \"\"\"\n",
    "    MPF loss for one sample (no inner function, no lambda)\n",
    "    \"\"\"\n",
    "    delta_e = compute_energy_differences_all_sites(sigma, h, j)\n",
    "    return jnp.sum(jnp.exp(-0.5 * beta * delta_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1472f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpf_loss(samples, h, j, beta=1.0):\n",
    "    \"\"\"\n",
    "    Average MPF loss over all samples\n",
    "    \"\"\"\n",
    "    return jnp.mean(jax.vmap(mpf_loss_per_sample, in_axes=(0, None, None, None))(samples, h, j, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "487524b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpf_gradients(samples, h, j, beta=1.0):\n",
    "    \"\"\"\n",
    "    Compute gradients of MPF loss w.r.t. h and j\n",
    "    \"\"\"\n",
    "    grad_loss = jax.grad(mpf_loss, argnums=(1, 2))\n",
    "    return grad_loss(samples, h, j, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "637b73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpf_step(params, opt_state, samples, optimizer, beta):\n",
    "    grad_h, grad_j = mpf_gradients(samples, params[\"h\"], params[\"j\"], beta)\n",
    "\n",
    "    grads = {\n",
    "        \"h\": grad_h,\n",
    "        \"j\": grad_j\n",
    "    }\n",
    "\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "\n",
    "    j = params[\"j\"]\n",
    "    j = 0.5 * (j + j.T)\n",
    "    j = j - jnp.diag(jnp.diag(j))\n",
    "    params[\"j\"] = j\n",
    "\n",
    "    return params, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "946fd84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_mpf(samples, h_init, j_init, n_steps=1000, lr=1e-2, beta=1.0):\n",
    "    params = {\n",
    "        \"h\": h_init,\n",
    "        \"j\": j_init\n",
    "    }\n",
    "\n",
    "    optimizer = optax.adam(lr)\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        params, opt_state = mpf_step(params, opt_state, samples, optimizer, beta)\n",
    "\n",
    "        if t % 100 == 0:\n",
    "            loss_val = mpf_loss(samples, params[\"h\"], params[\"j\"], beta)\n",
    "            print(f\"step {t} | loss = {loss_val:.6f}\")\n",
    "\n",
    "    return params[\"h\"], params[\"j\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "61f79840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0:[0.13100001215934753, -0.11100000888109207, -0.19500000774860382]\n",
      "[0.8360000252723694, -0.7870000600814819, -0.6600000262260437]\n",
      "0.14533334970474243\n",
      "\n",
      "step 500:[0.9600000381469727, -0.9460000395774841, -0.7820000648498535]\n",
      "[0.9850000739097595, -0.968000054359436, -0.7880000472068787]\n",
      "0.0009999871253967285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = 3\n",
    "n_samples = 100000\n",
    "\n",
    "h, j = dg.generate_log_concave_ising_params(d, sigma_h=1, sigma_j=0.5, seed=0)\n",
    "\n",
    "samples = dg.generate_ising_data(n_samples, h=h, j=j, n_steps=1000, beta=1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e40c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True h: [ 1.0040143 -0.9063372 -0.7481722]\n",
      "True J: [[ 0.         -1.225061   -0.35485688]\n",
      " [-1.225061    0.         -0.02253926]\n",
      " [-0.35485688 -0.02253926  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"True h:\", h)\n",
    "print(\"True J:\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ccb48ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | loss = 2.517921\n",
      "step 100 | loss = 1.061966\n",
      "step 200 | loss = 1.061922\n",
      "step 300 | loss = 1.061922\n",
      "step 400 | loss = 1.061922\n",
      "step 500 | loss = 1.061922\n",
      "step 600 | loss = 1.061922\n",
      "step 700 | loss = 1.061923\n",
      "step 800 | loss = 1.061922\n",
      "step 900 | loss = 1.061923\n",
      "Estimated h: [ 1.021      -0.901      -0.76600003]\n",
      "Estimated J: [[ 0.         -1.22       -0.33800003]\n",
      " [-1.22        0.         -0.028     ]\n",
      " [-0.33800003 -0.028       0.        ]]\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "h0 = 0.1 * jax.random.normal(key, shape=(d,))\n",
    "j0 = 0.1 * jax.random.normal(key, shape=(d, d))\n",
    "j0 = 0.5 * (j0 + j0.T)\n",
    "j0 = j0 - jnp.diag(jnp.diag(j0))\n",
    "\n",
    "h_est, j_est = optimize_mpf(samples, h0, j0, n_steps=1000, lr=0.1, beta=1.0)\n",
    "\n",
    "print(\"Estimated h:\", jnp.round(h_est, 3))\n",
    "print(\"Estimated J:\", jnp.round(j_est, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e4597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
