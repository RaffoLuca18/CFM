{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d9dee87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import data_gen as dg\n",
    "import ising as isg\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1757d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_langevin(x0, key, mu, L, eps=1e-2, n_steps=10):\n",
    "    \"\"\"\n",
    "    Evolve initial points x0 under Langevin dynamics defined by Gaussian potential.\n",
    "\n",
    "    Parameters:\n",
    "        x0: [N, d] array of particles\n",
    "        key: PRNGKey\n",
    "        mu: [d,] mean of target Gaussian\n",
    "        L: [d, d] lower-triangular matrix such that L @ L.T = precision\n",
    "        eps: step size\n",
    "        n_steps: number of Langevin steps\n",
    "\n",
    "    Returns:\n",
    "        x: evolved particles [N, d]\n",
    "    \"\"\"\n",
    "    def grad_V(x):\n",
    "        diff = x - mu\n",
    "        precision = L @ L.T\n",
    "        return diff @ precision.T\n",
    "\n",
    "    def step(x, key):\n",
    "        noise = jax.random.normal(key, shape=x.shape)\n",
    "        return x - eps * grad_V(x) + jnp.sqrt(2 * eps) * noise\n",
    "\n",
    "    def scan_fn(carry, _):\n",
    "        x, key = carry\n",
    "        key, subkey = jax.random.split(key)\n",
    "        x_new = step(x, subkey)\n",
    "        return (x_new, key), x_new\n",
    "\n",
    "    (x_final, _), _ = jax.lax.scan(scan_fn, (x0, key), None, length=n_steps)\n",
    "    return x_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a810f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sm_loss(params, samples):\n",
    "\n",
    "    mu = params[\"mu\"]\n",
    "    L = params[\"L\"]\n",
    "    Lambda = L @ L.T\n",
    "\n",
    "    centered = samples - mu\n",
    "    Lambda2 = Lambda @ Lambda\n",
    "    quad_terms = jnp.sum((centered @ Lambda2) * centered, axis=1)\n",
    "\n",
    "    loss = 0.5 * jnp.mean(quad_terms) - jnp.trace(Lambda)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7bbf9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_score_matching(samples, n_steps=1000, lr=1e-2, seed=0, n_enhance=200, eps=1e-2):\n",
    "\n",
    "    d = samples.shape[1]\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    key_mu, key_L, key_langevin = jax.random.split(key, 3)\n",
    "\n",
    "    mu_init = jax.random.normal(key_mu, shape=(d,))\n",
    "    L_init = jnp.eye(d) + 0.01 * jax.random.normal(key_L, shape=(d, d))\n",
    "    L_init = jnp.tril(L_init)\n",
    "\n",
    "    params = {\"mu\": mu_init, \"L\": L_init}\n",
    "    optimizer = optax.adam(lr)\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    loss_grad_fn = jax.value_and_grad(sm_loss)\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        loss_val, grads = loss_grad_fn(params, samples)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        params[\"L\"] = jnp.tril(params[\"L\"])\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step {step:4d} | Loss: {loss_val:.6f}\")\n",
    "\n",
    "        # Enhance samples every n_enhance steps\n",
    "        if (step + 1) % n_enhance == 0:\n",
    "            key_langevin, subkey = jax.random.split(key_langevin)\n",
    "            new_samples = evolve_langevin(samples, subkey, params[\"mu\"], params[\"L\"], eps=eps, n_steps=10)\n",
    "            samples = jnp.concatenate([samples, new_samples], axis=0)\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb3c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_score_matching_2(samples, n_steps=1000, lr=1e-2, seed=0,\n",
    "                            delta=1e-3, n_enhance=100, eps=1e-2):\n",
    "    d = samples.shape[1]\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    key_mu, key_L, key_langevin = jax.random.split(key, 3)\n",
    "\n",
    "    mu_init = jax.random.normal(key_mu, shape=(d,))\n",
    "    L_init = jnp.eye(d) + 0.01 * jax.random.normal(key_L, shape=(d, d))\n",
    "    L_init = jnp.tril(L_init)\n",
    "\n",
    "    params = {\"mu\": mu_init, \"L\": L_init}\n",
    "    optimizer = optax.adam(lr)\n",
    "    opt_state = optimizer.init(params)\n",
    "    loss_grad_fn = jax.value_and_grad(sm_loss)\n",
    "\n",
    "    prev_params = params\n",
    "    last_enhance_step = 0  # passo in cui è stato fatto l'ultimo enhance\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        loss_val, grads = loss_grad_fn(params, samples)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        params[\"L\"] = jnp.tril(params[\"L\"])\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step {step:4d} | Loss: {loss_val:.6f}\")\n",
    "\n",
    "        # Calcolo variazione dei parametri\n",
    "        delta_mu = jnp.linalg.norm(params[\"mu\"] - prev_params[\"mu\"])\n",
    "        delta_L = jnp.linalg.norm(params[\"L\"] - prev_params[\"L\"])\n",
    "        delta_theta = jnp.sqrt(delta_mu**2 + delta_L**2)\n",
    "\n",
    "        # Condizione per fare enhancement\n",
    "        if delta_theta < delta and (step - last_enhance_step) >= n_enhance:\n",
    "            key_langevin, subkey = jax.random.split(key_langevin)\n",
    "            new_samples = evolve_langevin(samples, subkey, params[\"mu\"], params[\"L\"], eps=eps, n_steps=10)\n",
    "            samples = jnp.concatenate([samples, new_samples], axis=0)\n",
    "            last_enhance_step = step\n",
    "            print(f\" ↳ Enhanced at step {step}, Δθ = {delta_theta:.2e}, total samples = {samples.shape[0]}\")\n",
    "\n",
    "        prev_params = params\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9771503f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0 | Loss: 0.040803\n",
      "Step   20 | Loss: -2.703758\n",
      "Step   40 | Loss: -3.844007\n",
      "Step   60 | Loss: -5.027158\n",
      "Step   80 | Loss: -6.266546\n",
      "Step  100 | Loss: -7.700078\n",
      "Step  120 | Loss: -9.402672\n",
      "Step  140 | Loss: -11.275608\n",
      "Step  160 | Loss: -13.190903\n",
      "Step  180 | Loss: -15.032191\n",
      "Step  200 | Loss: -16.705515\n",
      "Step  220 | Loss: -18.142570\n",
      "Step  240 | Loss: -19.304667\n",
      "Step  260 | Loss: -20.190701\n",
      "Step  280 | Loss: -20.818161\n",
      "Step  300 | Loss: -21.236916\n",
      "Step  320 | Loss: -21.493399\n",
      "Step  340 | Loss: -21.641241\n",
      "Step  360 | Loss: -21.720255\n",
      "Step  380 | Loss: -21.760279\n",
      "Step  400 | Loss: -21.779266\n",
      "Step  420 | Loss: -21.787777\n",
      "Step  440 | Loss: -21.791601\n",
      "Step  460 | Loss: -21.788071\n",
      " ↳ Enhanced at step 467, Δθ = 1.00e-03, total samples = 20\n",
      "Step  480 | Loss: -18.866550\n",
      "Step  500 | Loss: -19.309046\n",
      "Step  520 | Loss: -19.415136\n",
      "Step  540 | Loss: -19.450861\n",
      "Step  560 | Loss: -19.463461\n",
      "Step  580 | Loss: -19.468405\n",
      "Step  600 | Loss: -19.470299\n",
      " ↳ Enhanced at step 612, Δθ = 9.85e-04, total samples = 40\n",
      "Step  620 | Loss: -16.349253\n",
      "Step  640 | Loss: -16.677063\n",
      "Step  660 | Loss: -16.766727\n",
      "Step  680 | Loss: -16.792486\n",
      "Step  700 | Loss: -16.799063\n",
      "Step  720 | Loss: -16.801386\n",
      " ↳ Enhanced at step 730, Δθ = 9.98e-04, total samples = 80\n",
      "Step  740 | Loss: -14.210260\n",
      "Step  760 | Loss: -14.437372\n",
      "Step  780 | Loss: -14.504552\n",
      "Step  800 | Loss: -14.521501\n",
      "Step  820 | Loss: -14.526477\n",
      "Step  840 | Loss: -14.528005\n",
      " ↳ Enhanced at step 844, Δθ = 9.92e-04, total samples = 160\n",
      "Step  860 | Loss: -12.707872\n",
      "Step  880 | Loss: -12.818003\n",
      "Step  900 | Loss: -12.839252\n",
      "Step  920 | Loss: -12.845145\n",
      "Step  940 | Loss: -12.846747\n",
      " ↳ Enhanced at step 946, Δθ = 9.81e-04, total samples = 320\n",
      "Step  960 | Loss: -12.279722\n",
      "Step  980 | Loss: -12.318240\n"
     ]
    }
   ],
   "source": [
    "mu, cov = dg.generate_gaussian_params(d=5, sigma_mu=0.1, sigma_cov=0.2, seed=0)\n",
    "mu *= 10\n",
    "cov *= 10\n",
    "samples = dg.generate_gaussian_data(mu, cov, n_samples=10, seed=90)\n",
    "\n",
    "params_hat = optimize_score_matching_2(samples, n_steps=1000, lr=1e-2)\n",
    "\n",
    "mu_hat = params_hat[\"mu\"]\n",
    "precision_hat = params_hat[\"L\"] @ params_hat[\"L\"].T\n",
    "cov_hat = jnp.linalg.inv(precision_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1dd1e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.004  -0.9063 -0.7482 -1.1714 -0.8712] \n",
      "\n",
      " [ 0.6264 -0.247  -0.6261 -1.1498 -1.4398] 0.95704716 \n",
      "\n",
      "\n",
      "\n",
      "[[ 4.443   1.6469 -0.4872  1.2632  1.6904]\n",
      " [ 1.6469  3.7204 -0.4334 -0.8381 -0.5858]\n",
      " [-0.4872 -0.4334  1.4431  0.122  -0.803 ]\n",
      " [ 1.2632 -0.8381  0.122   2.6474  0.5179]\n",
      " [ 1.6904 -0.5858 -0.803   0.5179  2.1397]] \n",
      "\n",
      " [[ 3.9809  1.3209 -0.0283  2.5885  1.696 ]\n",
      " [ 1.3209  1.2494 -0.      0.3454  0.3211]\n",
      " [-0.0283 -0.      0.8584  0.07   -0.576 ]\n",
      " [ 2.5885  0.3454  0.07    2.9484  0.9746]\n",
      " [ 1.696   0.3211 -0.576   0.9746  1.3228]] 4.1126084 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jnp.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(jnp.round(mu, 4), \"\\n\\n\", jnp.round(mu_hat, 4), jnp.linalg.norm(mu - mu_hat), \"\\n\\n\\n\")\n",
    "print(jnp.round(cov, 4), \"\\n\\n\", jnp.round(cov_hat, 4), jnp.linalg.norm(cov - cov_hat), \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea32a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf6cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
