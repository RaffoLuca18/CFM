{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "770fd9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import data_gen as dg\n",
    "import ising as isg\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ea1104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_grad(samples, mu, cov):\n",
    "\n",
    "    diff = samples - mu\n",
    "    grad = jnp.linalg.solve(cov, diff.T).T\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9561d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_langevin(samples, mu, cov, eps=1e-2, n_evolution=1, seed=0):\n",
    "    \n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    evolved_samples = samples\n",
    "\n",
    "    for _ in range(n_evolution):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        grad = potential_grad(evolved_samples, mu, cov)\n",
    "        noise = jax.random.normal(subkey, shape=evolved_samples.shape)\n",
    "        evolved_samples = evolved_samples - eps * grad + jnp.sqrt(2 * eps) * noise\n",
    "\n",
    "    return evolved_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdc2de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_loss(params, samples):\n",
    "\n",
    "    mu = params[\"mu\"]\n",
    "    L = params[\"L\"]\n",
    "    precision = L @ L.T\n",
    "    cov = jnp.linalg.inv(precision)\n",
    "\n",
    "    evolved_samples = evolve_langevin(samples, mu, cov)\n",
    "\n",
    "    centered = evolved_samples - mu\n",
    "    precision2 = precision @ precision\n",
    "    quad_terms = jnp.sum((centered @ precision2) * centered, axis=1)\n",
    "\n",
    "    loss = 0.5 * jnp.mean(quad_terms) - jnp.trace(precision)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d509328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_score_matching(samples, n_steps=1000, lr=1e-2, seed=0):\n",
    "\n",
    "    d = samples.shape[1]\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    key_mu, key_L = jax.random.split(key)\n",
    "\n",
    "    mu_init = jax.random.normal(key_mu, shape=(d,))\n",
    "    L_init = jnp.eye(d) + 0.01 * jax.random.normal(key_L, shape=(d, d))\n",
    "\n",
    "    L_init = jnp.tril(L_init)\n",
    "\n",
    "    params = {\"mu\": mu_init, \"L\": L_init}\n",
    "    optimizer = optax.adam(lr)\n",
    "    opt_state = optimizer.init(params)\n",
    "\n",
    "    loss_grad_fn = jax.value_and_grad(lm_loss)\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        loss_val, grads = loss_grad_fn(params, samples)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "\n",
    "        params[\"L\"] = jnp.tril(params[\"L\"])\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step {step:4d} | Loss: {loss_val:.6f}\")\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68956369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0 | Loss: -0.464309\n",
      "Step   20 | Loss: -0.671532\n",
      "Step   40 | Loss: -1.050031\n",
      "Step   60 | Loss: -1.660648\n",
      "Step   80 | Loss: -2.131709\n",
      "Step  100 | Loss: -2.161872\n",
      "Step  120 | Loss: -2.167278\n",
      "Step  140 | Loss: -2.168020\n",
      "Step  160 | Loss: -2.168081\n",
      "Step  180 | Loss: -2.168081\n",
      "Step  200 | Loss: -2.168082\n",
      "Step  220 | Loss: -2.168082\n",
      "Step  240 | Loss: -2.168082\n",
      "Step  260 | Loss: -2.168082\n",
      "Step  280 | Loss: -2.168082\n"
     ]
    }
   ],
   "source": [
    "mu, cov = dg.generate_gaussian_params(d=1, sigma_mu=0.1, sigma_cov=0.2, seed=0)\n",
    "samples = dg.generate_gaussian_data(mu, cov, n_samples=500, seed=0)\n",
    "\n",
    "params_hat = optimize_score_matching(samples, n_steps=300, lr=1e-2)\n",
    "\n",
    "mu_hat = params_hat[\"mu\"]\n",
    "precision_hat = params_hat[\"L\"] @ params_hat[\"L\"].T\n",
    "cov_hat = jnp.linalg.inv(precision_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b6a8fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1004] \n",
      "\n",
      " [0.0837] 0.016668439 \n",
      "\n",
      "\n",
      "\n",
      "[[0.2486]] \n",
      "\n",
      " [[0.22]] 0.02860327 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jnp.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(jnp.round(mu, 4), \"\\n\\n\", jnp.round(mu_hat, 4), jnp.linalg.norm(mu - mu_hat), \"\\n\\n\\n\")\n",
    "print(jnp.round(cov, 4), \"\\n\\n\", jnp.round(cov_hat, 4), jnp.linalg.norm(cov - cov_hat), \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86419136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
