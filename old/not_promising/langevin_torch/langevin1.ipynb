{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dd90c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import data_gen as dg\n",
    "\n",
    "import torch\n",
    "import geomloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3c1497",
   "metadata": {},
   "source": [
    "# we start with the trivial_1 case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "914adf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langevin_step(sample, theta, eps):\n",
    "\n",
    "    noise = torch.randn_like(sample)\n",
    "\n",
    "    grad_V = sample - theta\n",
    "\n",
    "    return sample - eps * grad_V + torch.sqrt(torch.tensor(2 * eps)) * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c33131df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_langevin(samples, theta, eps=1e-2, n_evolution=10, seed=0):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    samples_evolved = samples.clone()\n",
    "\n",
    "    for i in range(n_evolution):\n",
    "        samples_evolved = langevin_step(samples_evolved, theta, eps)\n",
    "\n",
    "    return samples_evolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e29b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinkhorn_loss = geomloss.SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.05)\n",
    "\n",
    "def lm_loss(samples, theta):\n",
    "\n",
    "    evolved_samples = evolve_langevin(samples, theta)\n",
    "    if samples.ndim == 1:\n",
    "        samples = samples.unsqueeze(1)\n",
    "    if evolved_samples.ndim == 1:\n",
    "        evolved_samples = evolved_samples.unsqueeze(1)\n",
    "\n",
    "    return sinkhorn_loss(samples, evolved_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e978981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_optimize(samples, n_epochs=300, lr=1e-2):\n",
    "    \n",
    "    theta = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "    optimizer = torch.optim.Adam([theta], lr=lr)\n",
    "\n",
    "    for t in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = lm_loss(samples, theta)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if t % 50 == 0:\n",
    "            print(f\"step {t} | loss = {loss.item():.6f} | theta = {theta.item():.4f}\")\n",
    "\n",
    "    return theta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48c32c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | loss = 0.458554 | theta = 0.0100\n",
      "step 50 | loss = 0.414184 | theta = 0.5068\n",
      "step 100 | loss = 0.372991 | theta = 0.9924\n",
      "step 150 | loss = 0.334942 | theta = 1.4654\n",
      "step 200 | loss = 0.299885 | theta = 1.9257\n",
      "step 250 | loss = 0.267665 | theta = 2.3730\n",
      "step 300 | loss = 0.238133 | theta = 2.8074\n",
      "step 350 | loss = 0.211141 | theta = 3.2287\n",
      "step 400 | loss = 0.186544 | theta = 3.6368\n",
      "step 450 | loss = 0.164200 | theta = 4.0315\n",
      "step 500 | loss = 0.143971 | theta = 4.4128\n",
      "step 550 | loss = 0.125720 | theta = 4.7806\n",
      "step 600 | loss = 0.109314 | theta = 5.1348\n",
      "step 650 | loss = 0.094625 | theta = 5.4753\n",
      "step 700 | loss = 0.081526 | theta = 5.8021\n",
      "step 750 | loss = 0.069897 | theta = 6.1150\n",
      "step 800 | loss = 0.059618 | theta = 6.4142\n",
      "step 850 | loss = 0.050578 | theta = 6.6996\n",
      "step 900 | loss = 0.042666 | theta = 6.9712\n",
      "step 950 | loss = 0.035778 | theta = 7.2291\n",
      "step 1000 | loss = 0.029817 | theta = 7.4733\n",
      "step 1050 | loss = 0.024687 | theta = 7.7041\n",
      "step 1100 | loss = 0.020300 | theta = 7.9215\n",
      "step 1150 | loss = 0.016573 | theta = 8.1257\n",
      "step 1200 | loss = 0.013429 | theta = 8.3170\n",
      "step 1250 | loss = 0.010795 | theta = 8.4957\n",
      "step 1300 | loss = 0.008607 | theta = 8.6619\n",
      "step 1350 | loss = 0.006803 | theta = 8.8161\n",
      "step 1400 | loss = 0.005328 | theta = 8.9587\n",
      "step 1450 | loss = 0.004135 | theta = 9.0901\n",
      "step 1500 | loss = 0.003179 | theta = 9.2106\n",
      "step 1550 | loss = 0.002421 | theta = 9.3208\n",
      "step 1600 | loss = 0.001828 | theta = 9.4211\n",
      "step 1650 | loss = 0.001370 | theta = 9.5121\n",
      "step 1700 | loss = 0.001022 | theta = 9.5943\n",
      "step 1750 | loss = 0.000762 | theta = 9.6682\n",
      "step 1800 | loss = 0.000571 | theta = 9.7344\n",
      "step 1850 | loss = 0.000436 | theta = 9.7933\n",
      "step 1900 | loss = 0.000342 | theta = 9.8456\n",
      "step 1950 | loss = 0.000280 | theta = 9.8918\n",
      "step 2000 | loss = 0.000242 | theta = 9.9324\n",
      "step 2050 | loss = 0.000221 | theta = 9.9678\n",
      "step 2100 | loss = 0.000212 | theta = 9.9987\n",
      "step 2150 | loss = 0.000211 | theta = 10.0254\n",
      "step 2200 | loss = 0.000216 | theta = 10.0484\n",
      "step 2250 | loss = 0.000224 | theta = 10.0680\n",
      "step 2300 | loss = 0.000233 | theta = 10.0848\n",
      "step 2350 | loss = 0.000243 | theta = 10.0989\n",
      "step 2400 | loss = 0.000253 | theta = 10.1109\n",
      "step 2450 | loss = 0.000263 | theta = 10.1208\n",
      "step 2500 | loss = 0.000271 | theta = 10.1291\n",
      "step 2550 | loss = 0.000278 | theta = 10.1360\n",
      "step 2600 | loss = 0.000285 | theta = 10.1416\n",
      "step 2650 | loss = 0.000290 | theta = 10.1462\n",
      "step 2700 | loss = 0.000295 | theta = 10.1499\n",
      "step 2750 | loss = 0.000299 | theta = 10.1529\n",
      "step 2800 | loss = 0.000302 | theta = 10.1553\n",
      "step 2850 | loss = 0.000304 | theta = 10.1572\n",
      "step 2900 | loss = 0.000306 | theta = 10.1587\n",
      "step 2950 | loss = 0.000308 | theta = 10.1598\n",
      "\n",
      "final theta: 10.1607\n"
     ]
    }
   ],
   "source": [
    "true_theta = 10.0\n",
    "samples = torch.randn(500) + true_theta\n",
    "\n",
    "theta_hat = lm_optimize(samples, n_epochs=3000, lr=1e-2)\n",
    "\n",
    "print(f\"\\nfinal theta: {theta_hat.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
