{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4742e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import geomloss\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b354c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian_params(d, sigma_mu=0.1, sigma_cov=0.1, seed=0):\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    mu = sigma_mu * torch.randn(d)\n",
    "\n",
    "    A = sigma_cov * torch.randn(d, d)\n",
    "    cov = A @ A.T + 1e-2 * torch.eye(d)\n",
    "\n",
    "    return mu, cov\n",
    "\n",
    "def generate_gaussian_data(mu, cov, n_samples, seed=0):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    L = torch.linalg.cholesky(cov)\n",
    "    d = mu.shape[0]\n",
    "\n",
    "    z = torch.randn(n_samples, d)\n",
    "    samples = mu + z @ L.T\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd462d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_grad(samples, mu, cov):\n",
    "\n",
    "    diff = samples - mu\n",
    "    precision = torch.linalg.inv(cov)\n",
    "\n",
    "    grad = torch.linalg.solve(cov, diff.T).T\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7365b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_langevin(samples, mu, cov, eps=1e-2, n_evolution=1, seed=0):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    evolved_samples = samples.clone()\n",
    "\n",
    "    for i in range(n_evolution):\n",
    "        grad = potential_grad(evolved_samples, mu, cov)\n",
    "        noise = torch.randn_like(evolved_samples)\n",
    "        evolved_samples = evolved_samples - eps * grad + torch.sqrt(torch.tensor(2 * eps)) * noise\n",
    "\n",
    "    return evolved_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d028e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinkhorn_loss = geomloss.SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.1)\n",
    "energy_loss = geomloss.SamplesLoss(loss='energy')\n",
    "\n",
    "def lm_loss(samples, mu, cov):\n",
    "\n",
    "    evolved_samples = evolve_langevin(samples, mu, cov)\n",
    "\n",
    "    return energy_loss(samples, evolved_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b496b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_optimize(samples, n_epochs=1000, lr=1e-2, seed=10, eps=1e-2, plot_every=500):\n",
    "\n",
    "    d = samples.shape[1]\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    mu = torch.randn(d, requires_grad=True)\n",
    "    a = torch.randn(d, d, requires_grad=True)\n",
    "\n",
    "    optimizer = torch.optim.Adam([mu, a], lr=lr)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        cov = a.T @ a\n",
    "        loss = lm_loss(samples, mu, cov)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % plot_every == 0 or epoch == n_epochs - 1:\n",
    "            print(f\"epoch {epoch} | loss = {loss.item():.6f} | mean = {mu} | cov = {cov}\")\n",
    "\n",
    "    return mu.detach(), cov.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f89b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15.4100]) \n",
      "\n",
      " tensor([[0.3544]]) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "epoch 0 | loss = 0.013927 | mean = tensor([-0.5914], requires_grad=True) | cov = tensor([[1.0246]], grad_fn=<MmBackward0>)\n",
      "epoch 500 | loss = 0.004637 | mean = tensor([1.1505], requires_grad=True) | cov = tensor([[4.8351]], grad_fn=<MmBackward0>)\n",
      "epoch 1000 | loss = 0.004493 | mean = tensor([2.0515], requires_grad=True) | cov = tensor([[6.5231]], grad_fn=<MmBackward0>)\n",
      "epoch 1500 | loss = 0.004450 | mean = tensor([2.7948], requires_grad=True) | cov = tensor([[7.7272]], grad_fn=<MmBackward0>)\n",
      "epoch 2000 | loss = 0.004430 | mean = tensor([3.4765], requires_grad=True) | cov = tensor([[8.6654]], grad_fn=<MmBackward0>)\n",
      "epoch 2500 | loss = 0.004420 | mean = tensor([4.1342], requires_grad=True) | cov = tensor([[9.4064]], grad_fn=<MmBackward0>)\n",
      "epoch 3000 | loss = 0.004413 | mean = tensor([4.7882], requires_grad=True) | cov = tensor([[9.9671]], grad_fn=<MmBackward0>)\n",
      "epoch 3500 | loss = 0.004410 | mean = tensor([5.4601], requires_grad=True) | cov = tensor([[10.3487]], grad_fn=<MmBackward0>)\n",
      "epoch 4000 | loss = 0.004407 | mean = tensor([6.1714], requires_grad=True) | cov = tensor([[10.5302]], grad_fn=<MmBackward0>)\n",
      "epoch 4500 | loss = 0.004404 | mean = tensor([6.9440], requires_grad=True) | cov = tensor([[10.4571]], grad_fn=<MmBackward0>)\n",
      "epoch 5000 | loss = 0.004401 | mean = tensor([7.8139], requires_grad=True) | cov = tensor([[10.0369]], grad_fn=<MmBackward0>)\n",
      "epoch 5500 | loss = 0.004396 | mean = tensor([8.8509], requires_grad=True) | cov = tensor([[9.0971]], grad_fn=<MmBackward0>)\n",
      "epoch 6000 | loss = 0.004387 | mean = tensor([10.2602], requires_grad=True) | cov = tensor([[7.2600]], grad_fn=<MmBackward0>)\n",
      "epoch 6500 | loss = 0.004307 | mean = tensor([13.3019], requires_grad=True) | cov = tensor([[2.6335]], grad_fn=<MmBackward0>)\n",
      "epoch 7000 | loss = 0.000002 | mean = tensor([15.4099], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 7500 | loss = 0.000003 | mean = tensor([15.4098], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 8000 | loss = 0.000002 | mean = tensor([15.4104], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 8500 | loss = 0.000002 | mean = tensor([15.4101], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 9000 | loss = 0.000002 | mean = tensor([15.4101], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 9500 | loss = 0.000002 | mean = tensor([15.4106], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 10000 | loss = 0.000002 | mean = tensor([15.4108], requires_grad=True) | cov = tensor([[0.0422]], grad_fn=<MmBackward0>)\n",
      "epoch 10500 | loss = 0.000003 | mean = tensor([15.4105], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 11000 | loss = 0.000002 | mean = tensor([15.4098], requires_grad=True) | cov = tensor([[0.0419]], grad_fn=<MmBackward0>)\n",
      "epoch 11500 | loss = 0.000002 | mean = tensor([15.4097], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 12000 | loss = 0.000003 | mean = tensor([15.4102], requires_grad=True) | cov = tensor([[0.0419]], grad_fn=<MmBackward0>)\n",
      "epoch 12500 | loss = 0.000002 | mean = tensor([15.4108], requires_grad=True) | cov = tensor([[0.0422]], grad_fn=<MmBackward0>)\n",
      "epoch 13000 | loss = 0.000002 | mean = tensor([15.4096], requires_grad=True) | cov = tensor([[0.0420]], grad_fn=<MmBackward0>)\n",
      "epoch 13500 | loss = 0.000002 | mean = tensor([15.4106], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 14000 | loss = 0.000002 | mean = tensor([15.4108], requires_grad=True) | cov = tensor([[0.0420]], grad_fn=<MmBackward0>)\n",
      "epoch 14500 | loss = 0.000003 | mean = tensor([15.4092], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 15000 | loss = 0.000002 | mean = tensor([15.4106], requires_grad=True) | cov = tensor([[0.0419]], grad_fn=<MmBackward0>)\n",
      "epoch 15500 | loss = 0.000002 | mean = tensor([15.4106], requires_grad=True) | cov = tensor([[0.0422]], grad_fn=<MmBackward0>)\n",
      "epoch 16000 | loss = 0.000003 | mean = tensor([15.4095], requires_grad=True) | cov = tensor([[0.0424]], grad_fn=<MmBackward0>)\n",
      "epoch 16500 | loss = 0.000002 | mean = tensor([15.4107], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 17000 | loss = 0.000002 | mean = tensor([15.4097], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 17500 | loss = 0.000003 | mean = tensor([15.4094], requires_grad=True) | cov = tensor([[0.0417]], grad_fn=<MmBackward0>)\n",
      "epoch 18000 | loss = 0.000002 | mean = tensor([15.4089], requires_grad=True) | cov = tensor([[0.0422]], grad_fn=<MmBackward0>)\n",
      "epoch 18500 | loss = 0.000002 | mean = tensor([15.4104], requires_grad=True) | cov = tensor([[0.0420]], grad_fn=<MmBackward0>)\n",
      "epoch 19000 | loss = 0.000001 | mean = tensor([15.4102], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 19500 | loss = 0.000002 | mean = tensor([15.4094], requires_grad=True) | cov = tensor([[0.0423]], grad_fn=<MmBackward0>)\n",
      "epoch 20000 | loss = 0.000002 | mean = tensor([15.4103], requires_grad=True) | cov = tensor([[0.0420]], grad_fn=<MmBackward0>)\n",
      "epoch 20500 | loss = 0.000002 | mean = tensor([15.4103], requires_grad=True) | cov = tensor([[0.0420]], grad_fn=<MmBackward0>)\n",
      "epoch 21000 | loss = 0.000002 | mean = tensor([15.4112], requires_grad=True) | cov = tensor([[0.0418]], grad_fn=<MmBackward0>)\n",
      "epoch 21500 | loss = 0.000002 | mean = tensor([15.4100], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 22000 | loss = 0.000002 | mean = tensor([15.4087], requires_grad=True) | cov = tensor([[0.0422]], grad_fn=<MmBackward0>)\n",
      "epoch 22500 | loss = 0.000002 | mean = tensor([15.4098], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 23000 | loss = 0.000003 | mean = tensor([15.4115], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 23500 | loss = 0.000001 | mean = tensor([15.4104], requires_grad=True) | cov = tensor([[0.0420]], grad_fn=<MmBackward0>)\n",
      "epoch 24000 | loss = 0.000002 | mean = tensor([15.4093], requires_grad=True) | cov = tensor([[0.0423]], grad_fn=<MmBackward0>)\n",
      "epoch 24500 | loss = 0.000002 | mean = tensor([15.4093], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 25000 | loss = 0.000002 | mean = tensor([15.4098], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 25500 | loss = 0.000002 | mean = tensor([15.4104], requires_grad=True) | cov = tensor([[0.0420]], grad_fn=<MmBackward0>)\n",
      "epoch 26000 | loss = 0.000001 | mean = tensor([15.4096], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 26500 | loss = 0.000002 | mean = tensor([15.4097], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 27000 | loss = 0.000003 | mean = tensor([15.4094], requires_grad=True) | cov = tensor([[0.0422]], grad_fn=<MmBackward0>)\n",
      "epoch 27500 | loss = 0.000002 | mean = tensor([15.4086], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 28000 | loss = 0.000003 | mean = tensor([15.4110], requires_grad=True) | cov = tensor([[0.0420]], grad_fn=<MmBackward0>)\n",
      "epoch 28500 | loss = 0.000002 | mean = tensor([15.4099], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 29000 | loss = 0.000002 | mean = tensor([15.4105], requires_grad=True) | cov = tensor([[0.0422]], grad_fn=<MmBackward0>)\n",
      "epoch 29500 | loss = 0.000003 | mean = tensor([15.4102], requires_grad=True) | cov = tensor([[0.0423]], grad_fn=<MmBackward0>)\n",
      "epoch 30000 | loss = 0.000003 | mean = tensor([15.4095], requires_grad=True) | cov = tensor([[0.0422]], grad_fn=<MmBackward0>)\n",
      "epoch 30500 | loss = 0.000002 | mean = tensor([15.4105], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 31000 | loss = 0.000002 | mean = tensor([15.4107], requires_grad=True) | cov = tensor([[0.0420]], grad_fn=<MmBackward0>)\n",
      "epoch 31500 | loss = 0.000002 | mean = tensor([15.4100], requires_grad=True) | cov = tensor([[0.0420]], grad_fn=<MmBackward0>)\n",
      "epoch 32000 | loss = 0.000002 | mean = tensor([15.4111], requires_grad=True) | cov = tensor([[0.0421]], grad_fn=<MmBackward0>)\n",
      "epoch 32500 | loss = 0.000001 | mean = tensor([15.4105], requires_grad=True) | cov = tensor([[0.0420]], grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucaraffo/CFM/cfm_env/lib/python3.13/site-packages/geomloss/samples_loss.py:47: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"Creates a criterion that computes distances between sampled measures on a vector space.\n",
      "/Users/lucaraffo/CFM/cfm_env/lib/python3.13/site-packages/geomloss/kernel_samples.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"Implements kernel (\"gaussian\", \"laplacian\", \"energy\") norms between sampled measures.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m samples = generate_gaussian_data(mu_true, cov_true, n_samples=\u001b[32m500\u001b[39m, seed=\u001b[32m0\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(mu_true, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, cov_true, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m mu_hat, cov_hat = \u001b[43mlm_optimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--------- results: ---------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mmu true:     \u001b[39m\u001b[33m\"\u001b[39m, mu_true)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mlm_optimize\u001b[39m\u001b[34m(samples, n_epochs, lr, seed, eps, plot_every)\u001b[39m\n\u001b[32m     12\u001b[39m optimizer.zero_grad()\n\u001b[32m     13\u001b[39m cov = a.T @ a\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m loss = \u001b[43mlm_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m loss.backward()\n\u001b[32m     16\u001b[39m optimizer.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mlm_loss\u001b[39m\u001b[34m(samples, mu, cov)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlm_loss\u001b[39m(samples, mu, cov):\n\u001b[32m      6\u001b[39m     evolved_samples = evolve_langevin(samples, mu, cov)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menergy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevolved_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CFM/cfm_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CFM/cfm_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CFM/cfm_env/lib/python3.13/site-packages/geomloss/samples_loss.py:265\u001b[39m, in \u001b[36mSamplesLoss.forward\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    262\u001b[39m     α, x, β, y = α.unsqueeze(\u001b[32m0\u001b[39m), x.unsqueeze(\u001b[32m0\u001b[39m), β.unsqueeze(\u001b[32m0\u001b[39m), y.unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# Run --------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m values = \u001b[43mroutines\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mα\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mβ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblur\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblur\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreach\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreach\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiameter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdiameter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcluster_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcluster_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebias\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdebias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpotentials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpotentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels_x\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels_y\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# Make sure that the output has the correct shape ------------------------------------\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    288\u001b[39m     \u001b[38;5;28mself\u001b[39m.potentials\n\u001b[32m    289\u001b[39m ):  \u001b[38;5;66;03m# Return some dual potentials (= test functions) sampled on the input measures\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CFM/cfm_env/lib/python3.13/site-packages/geomloss/kernel_samples.py:117\u001b[39m, in \u001b[36mkernel_loss\u001b[39m\u001b[34m(α, x, β, y, blur, kernel, name, potentials, use_keops, ranges_xx, ranges_yy, ranges_xy, **kwargs)\u001b[39m\n\u001b[32m    108\u001b[39m     kernel = kernel_routines[name]\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# Center the point clouds just in case, to prevent numeric overflows:\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# N.B.: This may break user-provided kernels and comes at a non-negligible\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m#       cost for small problems, so let's disable this by default.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    115\u001b[39m \n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# (B,N,N) tensor\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m K_xx = \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdouble_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblur\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_keops\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_keops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m=\u001b[49m\u001b[43mranges_xx\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# (B,M,M) tensor\u001b[39;00m\n\u001b[32m    121\u001b[39m K_yy = kernel(\n\u001b[32m    122\u001b[39m     double_grad(y), y.detach(), blur=blur, use_keops=use_keops, ranges=ranges_yy\n\u001b[32m    123\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CFM/cfm_env/lib/python3.13/site-packages/geomloss/kernel_samples.py:82\u001b[39m, in \u001b[36menergy_kernel\u001b[39m\u001b[34m(x, y, blur, use_keops, ranges)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34menergy_kernel\u001b[39m(x, y, blur=\u001b[38;5;28;01mNone\u001b[39;00m, use_keops=\u001b[38;5;28;01mFalse\u001b[39;00m, ranges=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# N.B.: We never truncate the energy distance kernel\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[43mdistances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_keops\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_keops\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CFM/cfm_env/lib/python3.13/site-packages/geomloss/utils.py:63\u001b[39m, in \u001b[36mdistances\u001b[39m\u001b[34m(x, y, use_keops)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m squared_distances(x, y, use_keops=use_keops).sqrt()\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.sqrt(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclamp_min\u001b[49m\u001b[43m(\u001b[49m\u001b[43msquared_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-8\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "d = 1\n",
    "mu_true, cov_true = generate_gaussian_params(d, sigma_mu=10, sigma_cov=2, seed=0)\n",
    "samples = generate_gaussian_data(mu_true, cov_true, n_samples=500, seed=0)\n",
    "print(mu_true, \"\\n\\n\", cov_true, \"\\n\\n\\n\\n\")\n",
    "\n",
    "mu_hat, cov_hat = lm_optimize(samples, n_epochs=40000, lr=1e-2)\n",
    "\n",
    "print(\"\\n--------- results: ---------\")\n",
    "print(\"mu true:     \", mu_true)\n",
    "print(\"mu hat:  \", mu_hat)\n",
    "print(\"cov true:\\n\", cov_true)\n",
    "print(\"cov hat:\\n\", cov_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e1338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe27fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
